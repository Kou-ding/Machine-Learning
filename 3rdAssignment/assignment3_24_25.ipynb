{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQ7YzabwjTmk"
   },
   "source": [
    "## Εργασία 3 ##\n",
    "\n",
    "Καλωσήρθατε στην τρίτη σας εργασία. Η εργασία αυτή έχει σκοπό να σας βοηθήσει να εμπεδώσετε τα σύνολα μοντέλων.\n",
    "\n",
    "Στην εργασία αυτή θα πρέπει να συμπληρώσετε κώδικα Python 3 στα σημεία που αναφέρουν # YOUR CODE HERE. Μην τροποποιείτε τον κώδικα που βρίσκεται εκτός αυτών των περιοχών.\n",
    "\n",
    "Πρωτού παραδόσετε την εργασία σας σιγουρευτείτε ότι ο κώδικας σε όλα τα κελιά τρέχει σωστά. Για το σκοπό αυτό επιλέξτε από το μενού **Χρόνος εκτέλεσης (runtime) -> Επανεκίνηση περιόδου λειτουργίας και εκτέλεση όλων**.\n",
    "\n",
    "Συμπληρώστε το όνομα (**NAME**) και το **AEM** σας παρακάτω **εντός των διπλών εισαγωγικών**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1746886817118,
     "user": {
      "displayName": "Grigorios Tsoumakas",
      "userId": "13048321804834071528"
     },
     "user_tz": -180
    },
    "id": "3-rBqXXbjyR0"
   },
   "outputs": [],
   "source": [
    "NAME = \"Παπαδάκης Κωνσταντίνος Φώτιος\"\n",
    "AEM = \"10371\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egArYhcsTG-T"
   },
   "source": [
    "**1 (2 μονάδες)** Σε αυτήν την εργασία θα δουλέψουμε με ένα σύνολο δεδομένων δυαδικής ταξινόμησης, από το δημόσιο αποθετήριο δεδομένων και πειραμάτων μηχανικής μάθησης [openml.org](https://www.openml.org/). Μπορείτε να δείτε πως φορτώνουμε σύνολα δεδομένων από το openml.org μέσα από την sklearn μελετώντας την αντίστοιχη [τεκμηρίωση](https://scikit-learn.org/stable/datasets/loading_other_datasets.html#downloading-datasets-from-the-openml-org-repository). Συγκεκριμένα θέλουμε να δουλέψουμε με την έκδοση 1 του Pima Indians Diabetes Database, το οποίο αφορά τη διάγνωση διαβήτη. Χωρίστε το σύνολο δεδομένων σε δεδομένα εκπαίδευσης (X_train, y_train) και ελέγχου (X_test, y_test) σε ποσοστό 70% και 30% αντίστοιχα με τη συνάρτηση train_test_split (τιμή για random_state βάλτε 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1746888301102,
     "user": {
      "displayName": "Grigorios Tsoumakas",
      "userId": "13048321804834071528"
     },
     "user_tz": -180
    },
    "id": "qgaPtNAmTCX7",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3d34c1c83f83737a14a84cab85c7417",
     "grade": false,
     "grade_id": "cell-88ff30ee4cf342eb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fetch the diabetes dataset from OpenML\n",
    "diabetes = fetch_openml(name='diabetes', version=1)\n",
    "X, y = diabetes.data, diabetes.target\n",
    "# Split the dataset into training 70% and test 30% sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1746888305494,
     "user": {
      "displayName": "Grigorios Tsoumakas",
      "userId": "13048321804834071528"
     },
     "user_tz": -180
    },
    "id": "19LlgZx5cOLP",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b612cdb194e3a6d919b0f0119f34d18",
     "grade": true,
     "grade_id": "cell-25b0cfdbf7e65bfa",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Τεστ ορθής ανάγνωσης και διαχωρισμού του συνόλου δεδομένων\"\"\"\n",
    "assert X_train['mass'][0] == 33.6\n",
    "assert X_test['pedi'][34] == 0.512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RB8RexuPciQr"
   },
   "source": [
    "**2 (4 μονάδες)** Υλοποιήστε μια ντετερμινιστική εκδοχή της μεθόδου των τυχαίων υποχώρων, η οποία χτίζει τόσα μοντέλα όσες και οι μεταβλητές εισόδου, κάθε ένα από τα οποία αγνοεί και μία διαφορετική μεταβλητή εισόδου. Π.χ. το πρώτο μοντέλο αγνοεί την πρώτη, το δεύτερο αγνοεί τη δεύτερη κτλ. Χρησιμοποιήστε τη συνάρτηση clone από το sklearn.base για να δημιουργήστε αντίγραφο του βασικού μοντέλου σε κάθε επανάληψη. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1746888307073,
     "user": {
      "displayName": "Grigorios Tsoumakas",
      "userId": "13048321804834071528"
     },
     "user_tz": -180
    },
    "id": "KuC_s04KcigR",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5cade2ae8686482faea2a0be889b1bac",
     "grade": false,
     "grade_id": "cell-635611de8dc6fdf4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import clone\n",
    "\n",
    "class RandomSubspaceDet:\n",
    "    def __init__(self, estimator=DecisionTreeClassifier()):\n",
    "        # Initialize the class attributes\n",
    "        self.estimator = estimator\n",
    "        self.models = []\n",
    "        self.ignore_indices = []\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        # Reset the models and ignore indices\n",
    "        self.models = []\n",
    "        self.ignore_indices = []\n",
    "\n",
    "        # Get the number of features\n",
    "        n_features = X_train.shape[1]\n",
    "\n",
    "        # For each feature index i, remove the i-th column from X_train\n",
    "        for i in range(n_features):\n",
    "            # Remove the i-th feature from the training data\n",
    "            X_sub = np.delete(X_train, i, axis=1)\n",
    "            # Clone the estimator and fit it to the reduces data\n",
    "            model = clone(self.estimator)\n",
    "            model.fit(X_sub, y_train)\n",
    "            # Store the fitted model and the index of the ignored feature\n",
    "            self.models.append(model)\n",
    "            self.ignore_indices.append(i)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Initialize an empty list to store predictions\n",
    "        predictions = []\n",
    "\n",
    "        # For each trained model\n",
    "        for model, idx in zip(self.models, self.ignore_indices):\n",
    "            # Remove the i-th feature from the test data\n",
    "            X_sub = np.delete(X, idx, axis=1)\n",
    "            # Calculate the reduced input\n",
    "            preds = model.predict(X_sub)\n",
    "            # Append the predictions to the list\n",
    "            predictions.append(preds)\n",
    "\n",
    "        # Convert the list of predictions into a 2D NumPy array\n",
    "        predictions = np.array(predictions)\n",
    "\n",
    "        # Majority vote across models (row-wise mode)\n",
    "        final_preds = []\n",
    "        for i in range(predictions.shape[1]):\n",
    "            # Returns all unique predicted labels and their frequencies.\n",
    "            values, counts = np.unique(predictions[:, i], return_counts=True)\n",
    "            # Get the label with the highest frequency\n",
    "            majority_vote = values[np.argmax(counts)]\n",
    "            # Append this to the list of final predictions.\n",
    "            final_preds.append(majority_vote)\n",
    "\n",
    "        return np.array(final_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 755,
     "status": "ok",
     "timestamp": 1746888310415,
     "user": {
      "displayName": "Grigorios Tsoumakas",
      "userId": "13048321804834071528"
     },
     "user_tz": -180
    },
    "id": "iDNUeGUEciwi",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1e97b02cf57da7e715ddf6ba1b1ebe4",
     "grade": true,
     "grade_id": "cell-2cd50c46c4c0fd03",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Τεστ ορθής υλοποίησης RandomSubspaceDet\"\"\"\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "rs = RandomSubspaceDet(estimator=DecisionTreeClassifier(random_state=1))\n",
    "rs.fit(X_train, y_train)\n",
    "assert round(accuracy_score(rs.predict(X_test), y_test), 4) == 0.7446"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n19eEYRNRnG-"
   },
   "source": [
    "**3 (4 μονάδες)** Υλοποιήστε τη μέθοδο AdaBoost όπως παρουσιάστηκε στο μάθημα. Χρησιμοποιήστε τη συνάρτηση clone από το sklearn.base για να δημιουργήστε αντίγραφο του βασικού μοντέλου σε κάθε επανάληψη. Χρησιμοποιήστε την παράμετρο sample_weight της fit του βασικού μοντέλου για να ορίσετε τα βάρη των παραδειγμάτων εκπαίδευσης. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1746888312393,
     "user": {
      "displayName": "Grigorios Tsoumakas",
      "userId": "13048321804834071528"
     },
     "user_tz": -180
    },
    "id": "7NOoKPI8TBX6",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1ab09761b841c5f05458957fc1ebaf0",
     "grade": false,
     "grade_id": "cell-8e0c8663d7b7430f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import clone\n",
    "\n",
    "class AdaBoost:\n",
    "    def __init__(self, n_estimators=20, estimator=DecisionTreeClassifier(max_depth=1)):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.estimator = estimator\n",
    "        self.models = []\n",
    "        self.alphas = []\n",
    "        self.forward_map = {}\n",
    "        self.reverse_map = {}\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        y_train = np.array(y_train)\n",
    "\n",
    "        # Map the two classes to -1 and +1\n",
    "        classes = np.unique(y_train)\n",
    "        self.forward_map = {classes[0]: -1, classes[1]: 1}\n",
    "        self.reverse_map = {-1: classes[0], 1: classes[1]}\n",
    "        y_binary = np.vectorize(self.forward_map.get)(y_train)\n",
    "\n",
    "        n_samples = X_train.shape[0]\n",
    "        weights = np.ones(n_samples) / n_samples\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            model = clone(self.estimator)\n",
    "            model.fit(X_train, y_binary, sample_weight=weights)\n",
    "\n",
    "            y_pred = model.predict(X_train)\n",
    "            y_pred = np.sign(y_pred)  # ensure predictions are -1 or +1\n",
    "\n",
    "            # Compute weighted error\n",
    "            incorrect = (y_pred != y_binary)\n",
    "            err = np.dot(weights, incorrect)\n",
    "            err = max(err, 1e-10)\n",
    "\n",
    "            alpha = 0.5 * np.log((1 - err) / err)\n",
    "\n",
    "            # Update weights\n",
    "            weights *= np.exp(-alpha * y_binary * y_pred)\n",
    "            weights /= np.sum(weights)\n",
    "\n",
    "            self.models.append(model)\n",
    "            self.alphas.append(alpha)\n",
    "\n",
    "    def predict(self, X):\n",
    "        final_pred = np.zeros(X.shape[0])\n",
    "\n",
    "        for model, alpha in zip(self.models, self.alphas):\n",
    "            pred = model.predict(X)\n",
    "            pred = np.sign(pred)  # ensure -1 or +1\n",
    "            final_pred += alpha * pred\n",
    "\n",
    "        y_pred_binary = np.sign(final_pred)\n",
    "        y_pred_binary[y_pred_binary == 0] = 1  # resolve ties to class 1\n",
    "\n",
    "        return np.vectorize(self.reverse_map.get)(y_pred_binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1746888315804,
     "user": {
      "displayName": "Grigorios Tsoumakas",
      "userId": "13048321804834071528"
     },
     "user_tz": -180
    },
    "id": "jVjqVcv_tmYk",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d9bef2abfc7c0b25be8d2dbef07665b",
     "grade": true,
     "grade_id": "cell-a7bee06bbbf9666e",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Τεστ ορθής υλοποίησης AdaBoost\"\"\"\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "ab = AdaBoost(n_estimators=20, estimator=DecisionTreeClassifier(max_depth=2, random_state=1))\n",
    "ab.fit(X_train, y_train)\n",
    "assert round(accuracy_score(ab.predict(X_test), y_test), 4) == 0.7706 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2703,
     "status": "ok",
     "timestamp": 1746888649236,
     "user": {
      "displayName": "Grigorios Tsoumakas",
      "userId": "13048321804834071528"
     },
     "user_tz": -180
    },
    "id": "0QkPMoBNz3T5",
    "outputId": "37dbdff5-50a9-4250-f08a-c4386ff56488"
   },
   "outputs": [],
   "source": [
    "#Ίδιο αποτέλεσμα παίρνουμε και με την κλάση της sklearn. Ωστόσο υπάρχουν γενικότερα διαφορές στην υλοποίηση της σε σ΄χέση με αυτήν που είδαμε στη θεωρία, όπως η υποστήριξη παραπάνω από 2 κλάσεων και ο διαφορετικός χειρισμός της τυχαιότητας στην εκπαίδευση των επί μέρους μοντέλων.\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ab = AdaBoostClassifier(n_estimators=20, estimator=DecisionTreeClassifier(max_depth=2, random_state=1))\n",
    "ab.fit(X_train, y_train)\n",
    "assert round(accuracy_score(ab.predict(X_test), y_test), 4) == 0.7706"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOlLz270cvCPRc1g0UB5UtJ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
